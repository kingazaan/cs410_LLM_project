{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read in the 3 txt files and combine into 1\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# # os.chdir('sample_data')\n",
    "# read_files = glob.glob(\"sample_data/*.txt\")\n",
    "\n",
    "# with open(\"sample_data/combined.txt\", \"wb\") as outfile:\n",
    "#     for f in read_files:\n",
    "#         with open(f, \"rb\") as infile:\n",
    "#             outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Filename                                            Content\n",
      "0  7_1.txt  0:00\\n[SOUND] In this lecture we give an overv...\n",
      "1  7_2.txt  0:00\\n[SOUND] So, looking at the text mining p...\n",
      "2  7_3.txt  0:00\\n[SOUND]\\nPlay video starting at ::9 and ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azaan\\AppData\\Local\\Temp\\ipykernel_32240\\3844069920.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'Filename': filename, 'Content': content}, ignore_index=True)\n",
      "C:\\Users\\azaan\\AppData\\Local\\Temp\\ipykernel_32240\\3844069920.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'Filename': filename, 'Content': content}, ignore_index=True)\n",
      "C:\\Users\\azaan\\AppData\\Local\\Temp\\ipykernel_32240\\3844069920.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append({'Filename': filename, 'Content': content}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# import the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Directory path\n",
    "directory_path = 'C:\\\\Users\\\\azaan\\\\OneDrive\\\\Documents\\\\GitHub\\\\cs410_LLM_project\\\\sample_data'\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "df = pd.DataFrame(columns=['Filename', 'Content'])\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Read the content of the text file\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # Append a row to the DataFrame\n",
    "        df = df.append({'Filename': filename, 'Content': content}, ignore_index=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\azaan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\azaan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\azaan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# clean up words in dataset -- this includes removing stopwords\n",
    "import regex as re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, words, brown\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"words\")\n",
    "nltk.download(\"brown\")\n",
    "\n",
    "lemmer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# initialize dictionary\n",
    "global_dictionary  = set(words.words()) | set(brown.words())\n",
    "global_dictionary = {word.lower() for word in global_dictionary}\n",
    "remove_words = list(stop_words) # might need to use word_tokenize\n",
    "remove_words.extend(['Play', 'video', 'starting', 'at', '::', 'follow', 'transcript']) # add the common words that's include d in transcript\n",
    "\n",
    "# Now start actually cleaning the text\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase\n",
    "    text = text.replace('\\n', ' ') # remove newline indicator\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) # case\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text) # website\n",
    "    text = re.sub(r'(\\b\\w+\\b)(?: \\1)+', r'\\1', text) # remove duplicate next word after space\n",
    "    text = re.sub(r'\\b(?![aI]\\b)\\w\\b', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Remove stopwords and only keep words in dictionary\n",
    "def remove_terms(text):\n",
    "    text = clean_text(text)\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in remove_words] # remove stopwords\n",
    "    filtered_words = [word for word in filtered_words if word in global_dictionary] # remove if not in global dictionary\n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "df['Content'] = df['Content'].apply(remove_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sound lecture give overview text mining analytics play first lets define term text mining term text analytics title course called text mining analytics play two terms text mining text analytics actually roughly play really going really distinguish going use interchangeably reason chosen use terms title also subtle difference look two phrases literally play mining emphasizes process gives us error rate medical view problem analytics hand emphasizes result play problem mind going look text data help us solve problem play said treat two terms roughly play think literature probably find going really distinguish course play text mining text analytics mean want turn text data high quality information actionable knowledge play cases play problem dealing lot text data hope turn text data something useful us raw text data play distinguish two different results one information actionable knowledge play sometimes boundary two clear play also want say little bit play two different angles result text field mining play case high quality information refer concise information topic play might much easier humans digest raw text data example might face lot reviews product play concise form information would concise summary major opinions features product positive lets say battery life play kind results useful help people digest text data play minimize human effort consuming text data sense play kind output actually knowledge emphasize utility information knowledge discover text data play actionable knowledge decision problem actions take play example might able determine product appealing us better choice shocking decision play outcome could called actionable knowledge consumer take knowledge make decision act case text mining supplies knowledge optimal decision making two clearly distinguished dont necessarily make distinction play text mining also related text retrieval essential component many text mining systems play text retrieval refers finding relevant information large amount text data play taught another separate text retrieval search engines play discussed various techniques text retrieval play taken find overlap play useful know background text retrieval understanding topics text mining play taken also fine text mining analytics going repeat key concepts relevant text mining theyre high level also explain relation text retrieval text mining play text retrieval useful text mining two ways first text retrieval text mining meaning help us turn big text data relatively small amount relevant text data often whats needed solving particular problem play sense text retrieval also helps minimize human effort play text retrieval also needed knowledge provenance roughly corresponds interpretation text mining turning text data actionable knowledge find patterns text data actionable knowledge generally would verify knowledge looking original text data users would text retrieval support go back original text data interpret pattern better understand analogy verify whether pattern really reliable high level introduction concept text mining relationship text mining retrieval play next lets talk text data special kind data play interesting view text data data generated humans subjective sensors play slide shows analogy text data data humans subjective sensors physical sensors network sensor thermometer play general sensor would monitor real world way would sense signal real world would report signal data various forms example thermometer would watch temperature real world report temperature particular format play similarly geo sensor would sense location report location specification example form longitude value latitude value network sends monitor network traffic activities network reported digital format data similarly think humans subjective sensors observe real world perspective humans express observed form text data sense human actually subjective sensor would also sense whats happening world express whats observed form data case text data looking text data way advantage able integrate types data together thats indeed needed data mining problems play looking general problem data mining play general would dealing lot data world related problem general dealing data text data course data usually produced physical senses data also different formats play numerical data categorical relational data data like speech play non text data often important problems text data also important mostly contain lot symmetrical content often contain knowledge users especially preferences opinions users play treating text data data observed human sensors treat data together framework data mining problem basically turn data turn data actionable knowledge take advantage change real world course better means data mining problem basically taking lot data input giving actionable knowledge output inside data mining module also see number different kind mining different kinds data generally need different mining data play example data might require computer vision understand content would facilitate effective mining also lot general applicable kinds data course useful although particular kind data generally want also develop special algorithm course cover specialized particularly useful mining text data music'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bigrams and trigrams from data\n",
    "\n",
    "# Function to filter bigrams or trigrams\n",
    "def ngram_filter(ngram):\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    if not all(tag[1] in ['JJ', 'NN'] for tag in tags):\n",
    "        return False\n",
    "    if any(word in stop_words for word in ngram):\n",
    "        return False\n",
    "    if 'n' in ngram or 't' in ngram:\n",
    "        return False\n",
    "    if 'PRON' in ngram:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Function to find top ngrams\n",
    "def find_top_ngrams(texts, ngram_measures, min_freq=50, min_pmi=5, top_k=100):\n",
    "    finder = nltk.collocations.BigramCollocationFinder.from_documents(texts)\n",
    "    finder.apply_freq_filter(min_freq)\n",
    "    ngram_scores = finder.score_ngrams(ngram_measures.pmi)\n",
    "    filtered_ngrams = [ngram for ngram, pmi in ngram_scores if ngram_filter(ngram) and pmi > min_pmi]\n",
    "    return [' '.join(ngram) for ngram in filtered_ngrams][:top_k]\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "bigrams = find_top_ngrams([text.split() for text in df['Content']], bigram_measures)\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "trigrams = find_top_ngrams([text.split() for text in df['Content']], trigram_measures)\n",
    "\n",
    "# Function to replace ngrams in text\n",
    "def replace_ngrams(text):\n",
    "    for gram in trigrams:\n",
    "        text = text.replace(gram, '_'.join(gram.split()))\n",
    "    for gram in bigrams:\n",
    "        text = text.replace(gram, '_'.join(gram.split()))\n",
    "    return text\n",
    "\n",
    "# Apply ngram replacements to the text\n",
    "df['Grams'] = df['Content'].map(replace_ngrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize reviews + remove stop words + filter only nouns\n",
    "def tokenize_and_filter(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word.lower() not in stop_words and len(word) > 2]\n",
    "    pos_comment = nltk.pos_tag(words)\n",
    "    filtered = [word[0] for word in pos_comment if word[1] in ['NN']]\n",
    "    return filtered\n",
    "\n",
    "df['Grams'] = df['Grams'].map(tokenize_and_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9478e-43,  0.0000e+00,  1.9944e-07,  7.2167e-43,  2.6344e-43,\n",
       "          0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  5.9954e-36,  1.5165e-36,  8.9732e+11,\n",
       "         -3.9475e-42],\n",
       "        [ 0.0000e+00,  0.0000e+00,         nan,  0.0000e+00,  8.5479e-44,\n",
       "          5.6052e-45],\n",
       "        [ 3.5366e-04,  7.2167e-43,  1.7937e-43,  0.0000e+00,  9.5316e+11,\n",
       "         -4.3062e-42],\n",
       "        [ 2.6485e-43,  0.0000e+00,  3.1475e-06,  7.2167e-43,  3.5873e-43,\n",
       "          0.0000e+00],\n",
       "        [ 0.0000e+00,  0.0000e+00,  1.5165e-36,  1.5797e-37,  9.5745e+11,\n",
       "         -4.7406e-42]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some pytorch  training\n",
    "\n",
    "import torch\n",
    "randint = torch.randint(0, 10000, (6,1))\n",
    "tensor = torch.tensor([[5, 8, 7],  [4, 8, 6], [9, 8, 4]])\n",
    "zeros = torch.zeros([6,6])\n",
    "ones = torch.ones([6,6])\n",
    "arange = torch.arange(0, 10000)\n",
    "linspace = torch.linspace(0, 10000, steps=100)\n",
    "logspace = torch.logspace(-5000, 5000, steps=1000)\n",
    "eye = torch.eye(6)\n",
    "empty_like = torch.empty_like(eye)\n",
    "\n",
    "randint\n",
    "tensor\n",
    "zeros\n",
    "ones\n",
    "arange\n",
    "linspace\n",
    "logspace\n",
    "eye\n",
    "empty_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azaan\\AppData\\Local\\Temp\\ipykernel_32240\\3418477580.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  sample_softmax = F.softmax(sample)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3333, 0.3333, 0.3333])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device)\n",
    "import torch.nn as nn\n",
    "import  torch.nn.functional as F\n",
    "\n",
    "# more pytorch fucntions\n",
    "probabilities = torch.tensor([0.4, 0.6, 0.1])\n",
    "samples = torch.multinomial(probabilities, num_samples=7, replacement=True)\n",
    "ones = torch.ones([6,6])\n",
    "tril = torch.tril(ones)\n",
    "triu = torch.triu(ones)\n",
    "zeros = torch.zeros(6, 6)\n",
    "masked_fill = zeros.masked_fill(tril == 1, float(8))\n",
    "exp = torch.exp(masked_fill)\n",
    "transposed = tril.transpose(0, 1)\n",
    "stack = torch.stack([tril, triu, zeros])\n",
    "sample = torch.tensor([10., 10., 10.])\n",
    "linear = nn.Linear(3, 3, bias=False)\n",
    "sample_linear = linear(sample)\n",
    "sample_softmax = F.softmax(sample)\n",
    "\n",
    "samples\n",
    "ones\n",
    "tril\n",
    "triu\n",
    "zeros\n",
    "masked_fill\n",
    "exp\n",
    "transposed\n",
    "stack\n",
    "sample\n",
    "linear\n",
    "sample_linear\n",
    "sample_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now I will make embeddings for my words, let's see if it works\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "results = set()\n",
    "df['Grams'].apply(results.update)\n",
    "# print(len(results))\n",
    "\n",
    "# Create a vocabulary dictionary\n",
    "word_to_index = {word: idx for idx, word in enumerate(results)}\n",
    "\n",
    "# Convert words to indices in your DataFrame\n",
    "# AKA Encode these\n",
    "df['Grams_indices'] = df['Grams'].apply(lambda x: [word_to_index[word] for word in x])\n",
    "\n",
    "# Create a reverse dictionary\n",
    "index_to_word = {idx: word for word, idx in word_to_index.items()}\n",
    "\n",
    "# Function to convert indices back to words\n",
    "def indices_to_words(indices):\n",
    "    return [index_to_word[idx] for idx in indices]\n",
    "\n",
    "# # Apply the function to the 'Grams_indices' column\n",
    "# Aka Decode these grams\n",
    "# df['Decoded_Grams'] = df['Grams_indices'].apply(indices_to_words)\n",
    "\n",
    "# Pad sequences to a specified length (e.g., maxlen)\n",
    "maxlen = 50  # You can adjust this based on your data\n",
    "padded_indices = pad_sequence([torch.LongTensor(seq) for seq in df['Grams_indices']], batch_first=True, padding_value=0)\n",
    "\n",
    "vocab_size = len(results)\n",
    "embedding_dim = 11\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# embedded_indices = torch.LongTensor(df['Grams_indices'].tolist())\n",
    "embedded_grams = embedding(padded_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[160, 106,  83],\n",
       "        [312, 186, 161],\n",
       "        [166, 229,  91]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication examples with pytorch\n",
    "a = torch.tensor([[3, 4], [5, 8], [8, 3]])\n",
    "b = torch.tensor([[8, 26, 5], [34, 7, 17]])\n",
    "\n",
    "# form matmul, can do either below\n",
    "a @ b\n",
    "matmul = torch.matmul(a, b)\n",
    "\n",
    "matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 41,  28, 233, 281])\n",
      "tensor([[[-6.5571e-01, -3.7480e-01,  6.0739e-01, -6.6817e-01, -5.9260e-01,\n",
      "          -2.7353e+00,  1.9190e-01, -8.9298e-01, -1.0818e+00, -3.4203e-01,\n",
      "           9.5509e-01],\n",
      "         [-5.0029e-01,  1.0881e+00,  5.7089e-01, -2.2891e-01,  8.6399e-01,\n",
      "          -1.7891e+00, -7.4548e-01,  7.7717e-01, -3.3532e-01,  5.4402e-01,\n",
      "           2.1459e-02],\n",
      "         [-8.6783e-01, -2.1527e+00,  1.0966e+00,  4.5674e-01,  5.4685e-01,\n",
      "           1.4204e+00, -3.7695e-01, -2.4782e+00, -2.1762e+00,  1.2243e-01,\n",
      "           8.4708e-01],\n",
      "         [-4.8467e-01, -3.6913e-01,  1.2088e+00,  2.4618e-01, -1.0662e+00,\n",
      "           8.6203e-01,  7.8856e-02, -4.8550e-02, -8.2839e-01,  1.3926e-02,\n",
      "           1.9957e-02],\n",
      "         [-1.8060e-01, -5.9862e-01,  8.6913e-01,  1.3451e+00,  1.5062e+00,\n",
      "          -1.5742e+00, -1.6150e-01, -1.6652e+00, -9.4644e-01, -1.7916e-02,\n",
      "           2.1530e+00],\n",
      "         [ 7.5653e-01,  2.6278e+00, -7.6779e-01, -1.3161e+00,  6.4904e-01,\n",
      "           8.8990e-01,  1.9149e+00, -8.0168e-01,  8.5807e-01,  1.2859e+00,\n",
      "           1.3268e+00],\n",
      "         [ 2.7411e-01, -3.6149e-01, -9.6886e-01, -2.5977e-01, -1.3827e+00,\n",
      "           8.2949e-02, -6.8289e-02, -6.1713e-01, -2.9406e-01,  3.0820e+00,\n",
      "           2.1542e-01],\n",
      "         [-9.4844e-01, -3.7678e-01, -1.9643e-01, -2.9429e-01, -7.6095e-01,\n",
      "           5.2036e-01,  3.8713e-01, -9.8684e-03, -2.6349e-01,  9.9170e-01,\n",
      "           2.7644e-01]],\n",
      "\n",
      "        [[-9.5821e-01,  7.2692e-01, -7.0591e-01, -1.9029e-01, -6.0757e-01,\n",
      "           1.0567e-02,  2.6797e-02,  5.9070e-01, -4.7162e-01, -4.6552e-02,\n",
      "           4.9182e-01],\n",
      "         [-8.6783e-01, -2.1527e+00,  1.0966e+00,  4.5674e-01,  5.4685e-01,\n",
      "           1.4204e+00, -3.7695e-01, -2.4782e+00, -2.1762e+00,  1.2243e-01,\n",
      "           8.4708e-01],\n",
      "         [-5.0029e-01,  1.0881e+00,  5.7089e-01, -2.2891e-01,  8.6399e-01,\n",
      "          -1.7891e+00, -7.4548e-01,  7.7717e-01, -3.3532e-01,  5.4402e-01,\n",
      "           2.1459e-02],\n",
      "         [ 1.4263e+00, -2.5015e-01, -1.4200e+00, -3.4620e-01,  1.4700e+00,\n",
      "          -1.8884e+00, -6.2913e-01, -3.6826e-01,  7.0393e-02, -1.5615e-01,\n",
      "           1.0739e+00],\n",
      "         [-4.1611e-01,  4.9589e-01,  5.1155e-01,  7.9842e-01,  3.0620e-01,\n",
      "          -2.4236e-01,  1.1575e+00,  6.6767e-01,  7.5458e-02, -3.5252e-01,\n",
      "           8.1150e-01],\n",
      "         [-5.0029e-01,  1.0881e+00,  5.7089e-01, -2.2891e-01,  8.6399e-01,\n",
      "          -1.7891e+00, -7.4548e-01,  7.7717e-01, -3.3532e-01,  5.4402e-01,\n",
      "           2.1459e-02],\n",
      "         [ 2.7411e-01, -3.6149e-01, -9.6886e-01, -2.5977e-01, -1.3827e+00,\n",
      "           8.2949e-02, -6.8289e-02, -6.1713e-01, -2.9406e-01,  3.0820e+00,\n",
      "           2.1542e-01],\n",
      "         [ 7.6843e-02,  5.8178e-01,  8.7768e-04,  1.7849e-01, -8.3205e-01,\n",
      "          -1.1765e+00, -9.9785e-02, -1.1083e-01, -8.1148e-01, -1.2802e+00,\n",
      "          -1.7333e-01]],\n",
      "\n",
      "        [[ 2.7411e-01, -3.6149e-01, -9.6886e-01, -2.5977e-01, -1.3827e+00,\n",
      "           8.2949e-02, -6.8289e-02, -6.1713e-01, -2.9406e-01,  3.0820e+00,\n",
      "           2.1542e-01],\n",
      "         [ 2.7291e-01,  8.9007e-01, -1.3850e-01,  1.0767e-01,  2.6024e-01,\n",
      "          -7.2288e-01,  4.2793e-01,  1.3471e+00,  1.1245e-01, -2.0604e+00,\n",
      "          -1.1784e+00],\n",
      "         [ 9.8107e-02,  1.8964e+00, -9.9452e-01,  4.5341e-01,  5.5442e-01,\n",
      "          -1.6848e+00,  1.0450e+00, -2.3638e-01, -3.5406e-01,  4.0363e-01,\n",
      "          -2.7317e-02],\n",
      "         [-1.3388e+00,  2.4397e-01,  3.0327e-01,  7.9805e-01, -1.1849e-01,\n",
      "           9.9167e-01, -5.4892e-01, -5.0575e-01, -1.9307e-01,  1.7691e-01,\n",
      "           1.6476e-01],\n",
      "         [-7.6287e-01,  4.5493e-01,  1.0240e-01,  3.4710e-02, -1.4317e+00,\n",
      "          -1.5983e-01, -1.1213e+00, -3.8420e-01,  1.0920e+00,  1.1858e+00,\n",
      "          -8.1681e-01],\n",
      "         [ 7.6843e-02,  5.8178e-01,  8.7768e-04,  1.7849e-01, -8.3205e-01,\n",
      "          -1.1765e+00, -9.9785e-02, -1.1083e-01, -8.1148e-01, -1.2802e+00,\n",
      "          -1.7333e-01],\n",
      "         [-8.6783e-01, -2.1527e+00,  1.0966e+00,  4.5674e-01,  5.4685e-01,\n",
      "           1.4204e+00, -3.7695e-01, -2.4782e+00, -2.1762e+00,  1.2243e-01,\n",
      "           8.4708e-01],\n",
      "         [ 7.6843e-02,  5.8178e-01,  8.7768e-04,  1.7849e-01, -8.3205e-01,\n",
      "          -1.1765e+00, -9.9785e-02, -1.1083e-01, -8.1148e-01, -1.2802e+00,\n",
      "          -1.7333e-01]],\n",
      "\n",
      "        [[ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00]]], grad_fn=<StackBackward0>)\n",
      "tensor([[[-5.0029e-01,  1.0881e+00,  5.7089e-01, -2.2891e-01,  8.6399e-01,\n",
      "          -1.7891e+00, -7.4548e-01,  7.7717e-01, -3.3532e-01,  5.4402e-01,\n",
      "           2.1459e-02],\n",
      "         [-8.6783e-01, -2.1527e+00,  1.0966e+00,  4.5674e-01,  5.4685e-01,\n",
      "           1.4204e+00, -3.7695e-01, -2.4782e+00, -2.1762e+00,  1.2243e-01,\n",
      "           8.4708e-01],\n",
      "         [-4.8467e-01, -3.6913e-01,  1.2088e+00,  2.4618e-01, -1.0662e+00,\n",
      "           8.6203e-01,  7.8856e-02, -4.8550e-02, -8.2839e-01,  1.3926e-02,\n",
      "           1.9957e-02],\n",
      "         [-1.8060e-01, -5.9862e-01,  8.6913e-01,  1.3451e+00,  1.5062e+00,\n",
      "          -1.5742e+00, -1.6150e-01, -1.6652e+00, -9.4644e-01, -1.7916e-02,\n",
      "           2.1530e+00],\n",
      "         [ 7.5653e-01,  2.6278e+00, -7.6779e-01, -1.3161e+00,  6.4904e-01,\n",
      "           8.8990e-01,  1.9149e+00, -8.0168e-01,  8.5807e-01,  1.2859e+00,\n",
      "           1.3268e+00],\n",
      "         [ 2.7411e-01, -3.6149e-01, -9.6886e-01, -2.5977e-01, -1.3827e+00,\n",
      "           8.2949e-02, -6.8289e-02, -6.1713e-01, -2.9406e-01,  3.0820e+00,\n",
      "           2.1542e-01],\n",
      "         [-9.4844e-01, -3.7678e-01, -1.9643e-01, -2.9429e-01, -7.6095e-01,\n",
      "           5.2036e-01,  3.8713e-01, -9.8684e-03, -2.6349e-01,  9.9170e-01,\n",
      "           2.7644e-01],\n",
      "         [-6.5079e-01,  1.0401e+00, -1.0554e+00, -1.9512e+00,  1.0184e+00,\n",
      "           1.4091e-01, -2.8264e-01, -1.6149e+00,  5.2071e-01,  1.2359e+00,\n",
      "           1.3126e+00]],\n",
      "\n",
      "        [[-8.6783e-01, -2.1527e+00,  1.0966e+00,  4.5674e-01,  5.4685e-01,\n",
      "           1.4204e+00, -3.7695e-01, -2.4782e+00, -2.1762e+00,  1.2243e-01,\n",
      "           8.4708e-01],\n",
      "         [-5.0029e-01,  1.0881e+00,  5.7089e-01, -2.2891e-01,  8.6399e-01,\n",
      "          -1.7891e+00, -7.4548e-01,  7.7717e-01, -3.3532e-01,  5.4402e-01,\n",
      "           2.1459e-02],\n",
      "         [ 1.4263e+00, -2.5015e-01, -1.4200e+00, -3.4620e-01,  1.4700e+00,\n",
      "          -1.8884e+00, -6.2913e-01, -3.6826e-01,  7.0393e-02, -1.5615e-01,\n",
      "           1.0739e+00],\n",
      "         [-4.1611e-01,  4.9589e-01,  5.1155e-01,  7.9842e-01,  3.0620e-01,\n",
      "          -2.4236e-01,  1.1575e+00,  6.6767e-01,  7.5458e-02, -3.5252e-01,\n",
      "           8.1150e-01],\n",
      "         [-5.0029e-01,  1.0881e+00,  5.7089e-01, -2.2891e-01,  8.6399e-01,\n",
      "          -1.7891e+00, -7.4548e-01,  7.7717e-01, -3.3532e-01,  5.4402e-01,\n",
      "           2.1459e-02],\n",
      "         [ 2.7411e-01, -3.6149e-01, -9.6886e-01, -2.5977e-01, -1.3827e+00,\n",
      "           8.2949e-02, -6.8289e-02, -6.1713e-01, -2.9406e-01,  3.0820e+00,\n",
      "           2.1542e-01],\n",
      "         [ 7.6843e-02,  5.8178e-01,  8.7768e-04,  1.7849e-01, -8.3205e-01,\n",
      "          -1.1765e+00, -9.9785e-02, -1.1083e-01, -8.1148e-01, -1.2802e+00,\n",
      "          -1.7333e-01],\n",
      "         [ 2.7411e-01, -3.6149e-01, -9.6886e-01, -2.5977e-01, -1.3827e+00,\n",
      "           8.2949e-02, -6.8289e-02, -6.1713e-01, -2.9406e-01,  3.0820e+00,\n",
      "           2.1542e-01]],\n",
      "\n",
      "        [[ 2.7291e-01,  8.9007e-01, -1.3850e-01,  1.0767e-01,  2.6024e-01,\n",
      "          -7.2288e-01,  4.2793e-01,  1.3471e+00,  1.1245e-01, -2.0604e+00,\n",
      "          -1.1784e+00],\n",
      "         [ 9.8107e-02,  1.8964e+00, -9.9452e-01,  4.5341e-01,  5.5442e-01,\n",
      "          -1.6848e+00,  1.0450e+00, -2.3638e-01, -3.5406e-01,  4.0363e-01,\n",
      "          -2.7317e-02],\n",
      "         [-1.3388e+00,  2.4397e-01,  3.0327e-01,  7.9805e-01, -1.1849e-01,\n",
      "           9.9167e-01, -5.4892e-01, -5.0575e-01, -1.9307e-01,  1.7691e-01,\n",
      "           1.6476e-01],\n",
      "         [-7.6287e-01,  4.5493e-01,  1.0240e-01,  3.4710e-02, -1.4317e+00,\n",
      "          -1.5983e-01, -1.1213e+00, -3.8420e-01,  1.0920e+00,  1.1858e+00,\n",
      "          -8.1681e-01],\n",
      "         [ 7.6843e-02,  5.8178e-01,  8.7768e-04,  1.7849e-01, -8.3205e-01,\n",
      "          -1.1765e+00, -9.9785e-02, -1.1083e-01, -8.1148e-01, -1.2802e+00,\n",
      "          -1.7333e-01],\n",
      "         [-8.6783e-01, -2.1527e+00,  1.0966e+00,  4.5674e-01,  5.4685e-01,\n",
      "           1.4204e+00, -3.7695e-01, -2.4782e+00, -2.1762e+00,  1.2243e-01,\n",
      "           8.4708e-01],\n",
      "         [ 7.6843e-02,  5.8178e-01,  8.7768e-04,  1.7849e-01, -8.3205e-01,\n",
      "          -1.1765e+00, -9.9785e-02, -1.1083e-01, -8.1148e-01, -1.2802e+00,\n",
      "          -1.7333e-01],\n",
      "         [-5.0029e-01,  1.0881e+00,  5.7089e-01, -2.2891e-01,  8.6399e-01,\n",
      "          -1.7891e+00, -7.4548e-01,  7.7717e-01, -3.3532e-01,  5.4402e-01,\n",
      "           2.1459e-02]],\n",
      "\n",
      "        [[ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00],\n",
      "         [ 5.0396e-01, -4.2063e-01, -3.2695e-01, -1.8314e-01,  1.8145e+00,\n",
      "           1.4553e+00, -8.0798e-02,  1.1995e+00, -4.7285e-01, -7.6503e-01,\n",
      "          -1.2575e+00]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# make a batch\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "\n",
    "# not sure if I should use the embedded grams for this batch\n",
    "# Flatten the embedded_grams tensor\n",
    "data = embedded_grams.view(-1, embedded_grams.size(-1))\n",
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "# print(len(data))\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    print(ix)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to make a simple bigram model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table == nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
