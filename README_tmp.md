# CS 410 LLM Project
This is the repository of our CS 410 LLM project. This project transforms the transcripts of Fall 2023 CS 410 online lectures into a dataset and preprocesses it before using it to train a LLM model that can take a CS 410 - related question input and generate answers.

## Dataset
The `data` folder stores the crude data gleaned from the video transcripts of the CS 410 lectures. `all_lectures.csv` aligns each piece of transcript text with the week number, lesson number and lesson title as introduced in the Fall 2023 offering of CS 410 @ UIUC. These data are to be preprocessed by the LLM model. The `sample_data` folder contains some variants of a segment of our data that can be used for demoing or testing.

## Model
The model implementation and testing lies in the `scripts` folder.
- `testing_llm.ipynb` contains the implementation of the LLM model. It includes code to preprocess the dataset (e.g. word tokenization), the setup of the neural-network-based LLM model (with multiple variants, including scaled dot-product attention, multi-head attention and GPT), and a `Flask` frontend for users. 
- `testing_QA_finetuning.ipynb` attempts to fine-tune a snapshot of a trained model by creating a QA model.
- `testing_bigram.ipynb` makes a bigram model (instead of the unigram models in `testing_llm.ipynb`) to parse pairs of consecutive words in the cleaned dataset.
- `testing_pretrained_llm.ipynb` attempts to test our dataset on a pretrained LLM.
- `time_testing.py` is a simple script to keep track of the time elapsed during training.

## Evaluation
After releasing this LLM model, we would like to glean feedback from actual users to evaluate the effectiveness of the answers generated by our LLM. We trained a CNN model (in the `CNN` folder) to perform sentiment analysis. Since we don't have actual comments from users yet, we used movie reviews to benchmark the CNN model temporarily.